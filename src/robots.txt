# www.robotstxt.org/

# Allow crawling of all content
# Change to 'Disallow: /' 
# The "Disallow: /" tells the robot that it should not visit any pages on the site.
User-agent: *
Disallow: /
